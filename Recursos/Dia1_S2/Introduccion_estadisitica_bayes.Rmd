---
title: "Introducción a los modelos de estimación en Áreas Pequeñas (SAE)"
author: "Andrés Gutierrez y Stalyn Guerrero"
date: "`r Sys.Date()`"
format: 
  revealjs:
    theme: simple
    transition: fade
    slide-number: true
    toc: false
    css: styles.css
    width: 1500
    height: 1000
    margin: 0.1
    center: false
    navigationMode: linear
    controlsLayout: edges
    controlsTutorial: false
    hash: true
bibliography: references.bib
csl: C:\\Users\\sguerrero\\Documents/.quarto/styles\\apa.csl
---


```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE
)

tba <- function(dat, cap = NA){
  kable(dat,
      format = "html", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = F)%>%
         kable_classic(full_width = F, html_font = "Arial Narrow")
}
library(rstan)
library(knitr)
library(kableExtra)
library(tidyverse)
```


# Introducción

## Introducción

* La **Estimación en Áreas Pequeñas (SAE)** se ha consolidado como una herramienta esencial para producir indicadores socioeconómicos y demográficos en dominios con muestras reducidas.

* La **inferencia Bayesiana**, apoyada en métodos de **Monte Carlo mediante Cadenas de Markov (MCMC)**, permite aproximar distribuciones posteriores complejas en modelos jerárquicos.

## Desafíos principales:

* Convergencia y eficiencia de las cadenas MCMC.

* Calidad de estimaciones en indicadores clave como pobreza, ingreso medio y desempleo.

* Un aspecto crítico es el **benchmarking**, que asegura la coherencia entre estimaciones desagregadas (ej. municipios, etnias) y totales agregados (ej. departamentos, nivel nacional).

* Aunque no mejora la precisión intrínseca, el benchmarking garantiza comparabilidad y consistencia con fuentes externas confiables.

# Modelos de área 

## Modelos de área

Los modelos de área constituyen una clase de modelos jerárquicos utilizados en el marco de la Estimación en Áreas Pequeñas (SAE), cuyo objetivo es mejorar la precisión de los estimadores directos cuando los tamaños muestrales dentro de los dominios son insuficientes para obtener inferencias confiables bajo métodos clásicos de encuesta.
 

## Condiciones para el modelos de área 

Los modelos de área asumen que para cada dominio $d = 1, \dots, D$ se dispone de:

- Un **estimador directo** $\hat{Y}_d$, obtenido a partir de la encuesta, y  

- Su correspondiente **varianza de muestreo** estimada $\psi_d = \text{Var}(\hat{Y}_d)$.  

La estructura del modelo se plantea a nivel **agregado** (área o dominio), incorporando información auxiliar proveniente de fuentes complementarias —como censos de población, registros administrativos o bases satelitales—, usualmente disponible en todos los dominios.  

## Objetivo del modelo de área 

El modelos de área tiene por objetivo “suavizar” las estimaciones directas mediante la combinación lineal de la información observada y la información modelada, lo que se traduce en predictores con menor error cuadrático medio (MSE) respecto a las estimaciones puramente directas.  


## Modelo clásico de @fay1979estimates

- La unidad de análisis es el dominio geográfico o administrativo (por ejemplo, departamento, municipio o parroquia), y el número de observaciones suele corresponder al número total de dominios incluidos en el análisis.  

- Estructura jerárquica:

$$
\begin{aligned}
\text{Nivel de muestreo: } & \hat{Y}_d = \theta_d + e_d, \quad e_d \sim N(0, \psi_d) \\
\text{Nivel del modelo: } & \theta_d = \mathbf{x}_d^{\top}\boldsymbol{\beta} + u_d, \quad u_d \sim N(0, \sigma_u^2)
\end{aligned}
$$

Donde:  
- $\hat{Y}_d$: estimador directo en el dominio $d$.  
- $\psi_d$: varianza de muestreo (conocida o estimada).  
- $\mathbf{x}_d$: vector de covariables auxiliares.  
- $u_d$: efecto aleatorio entre áreas.  


## Intuición del modelo

El **modelo de FH** su estimador empírico, conocido como *Empirical Best Linear Unbiased Predictor (EBLUP)*, combina de manera óptima la información directa y auxiliar mediante un factor de ponderación dependiente de la precisión de cada área:  

- Produce un estimador suavizado:  

$$
\tilde{Y}_d = \gamma_d \hat{Y}_d + (1 - \gamma_d)\mathbf{x}_d^{\top}\hat{\boldsymbol{\beta}}
$$
  donde $\gamma_d = \frac{\sigma_u^2}{\sigma_u^2 + \psi_d}$. 

## Observación sobre $\gamma_d$

- Áreas con *alta varianza muestral* (muestras pequeñas) reciben mayor peso del modelo, 

- Áreas con *baja varianza muestral* (muestras grandes) conservan más peso de la estimación directa.  

La combinación de información a través de dominios permite reducir la variabilidad de las estimaciones y mejorar la estabilidad espacial y temporal de los indicadores.   


## Consideraciones y limitaciones

- Depende de la calidad de las covariables auxiliares.  

- Requiere varianzas de muestreo confiables ($\psi_d$).  

- Supone normalidad e independencia entre áreas.  

- No corrige sesgos sistemáticos en los datos originales.  


## Implementación práctica

- Los modelos de área pueden estimarse bajo dos enfoques:  
  
  - Frecuentista: mediante el *Best Linear Unbiased Predictor (BLUP)*.  
  
  - **Bayesiano:** usando el *posterior mean predictor*, estimado con MCMC.  

- En la práctica, se implementan con paquetes como `sae`, `hbsae`, `brms` o `rstan`.  

- El marco Bayesiano permite:

  - Incorporar incertidumbre completa sobre los parámetros.  

  - Modelar estructuras más complejas (espacio, tiempo, correlación).  

  - Obtener intervalos creíbles más interpretables.  


# Fundamentos de la inferencia Bayesiana en R y STAN


## Regla de Bayes (I)

* Objetivo: inferir el vector de parámetros $\boldsymbol{\theta}$ a partir de los datos $\mathbf{Y}$.

$$
p(\boldsymbol{\theta},\mathbf{Y})=p(\boldsymbol{\theta})p(\mathbf{Y} \mid \boldsymbol{\theta})
$$

-   La distribución $p(\boldsymbol{\theta})$ se le conoce con el nombre de distribución previa.

-   El término $p(\mathbf{Y} \mid \boldsymbol{\theta})$ es la distribución de muestreo, verosimilitud o distribución de los datos.

## Regla de Bayes (II)

-   La distribución del vector de parámetros condicionada a los datos observados está dada por

    $$
    p(\boldsymbol{\theta} \mid \mathbf{Y})=\frac{p(\boldsymbol{\theta},\mathbf{Y})}{p(\mathbf{Y})}=\frac{p(\boldsymbol{\theta})p(\mathbf{Y} \mid \boldsymbol{\theta})}{p(\mathbf{Y})}
    $$

- Distribución posterior (actualización tras observar los datos):

$$
p(\boldsymbol{\theta} \mid \mathbf{Y}) \propto p(\mathbf{Y} \mid \boldsymbol{\theta})\, p(\boldsymbol{\theta})
$$

## Inferencia Bayesiana.

En términos de estimación, inferencia y predicción, el enfoque Bayesiano supone dos momentos o etapas:

1. **Antes de recolectar datos:** se propone una distribución previa según conocimiento o información externa.

2. **Después de recolectar datos:** se actualiza el conocimiento mediante la distribución posterior.


## Modelos uniparamétricos


* Definición: modelos con un único parámetro $\theta \in \mathbb{R}$.

### Modelo Bernoulli

* Variable aleatoria: $Y \sim \text{Bernoulli}(\theta)$

$$
p(Y \mid \theta) = \theta^y (1-\theta)^{1-y},\quad y\in\{0,1\}
$$

* Distribución previa de $\theta$ (Beta o uniforme):

$$
p(\theta \mid \alpha, \beta) = \frac{1}{\text{Beta}(\alpha,\beta)} \theta^{\alpha-1} (1-\theta)^{\beta-1}, \quad \theta \in [0,1]
$$

## Modelos uniparamétricos

* Distribución posterior con una observación $Y$:

$$
\theta \mid Y \sim \text{Beta}(y+\alpha, \beta - y + 1)
$$

* Distribución posterior con muestra de $n$ observaciones $Y_1,\dots,Y_n$:

$$
\theta \mid Y_1,\dots,Y_n \sim \text{Beta}\Big(\sum_{i=1}^n y_i + \alpha, \beta - \sum_{i=1}^n y_i + n\Big)
$$



## Ejemplo

### Objetivo

* Estimar la **proporción de personas bajo la línea de pobreza**:

$$
P_d = \frac{\sum_{U_d} y_{di}}{N_d}, \quad y_{di} =
\begin{cases} 
1 & \text{si ingreso} < \text{línea de pobreza} \\ 
0 & \text{en otro caso} 
\end{cases}
$$

## Descomposición

* Promedio poblacional por dominio $d$:

$$
\bar{Y}_d = P_d = \frac{\sum_{s_d} y_{di} + \sum_{s^c_d} y_{di}}{N_d}
$$

* $s_d$: muestra observada
* $s_d^c$: población no observada


## Estimación mediante modelo

* Estimador de $P_d$:

$$
\hat{P}_d = \frac{\sum_{s_d} y_{di} + \sum_{s^c_d} \hat{y}_{di}}{N_d}
$$

* Valores predichos para no observados:

$$
\hat{y}_{di} = E_{\mathscr{M}}(y_{di} \mid \mathbf{x}_d, \boldsymbol{\beta})
$$

* $\mathscr{M}$: distribución probabilística inducida por el modelo
* $\mathbf{x}_d$: covariables del dominio $d$
* $\boldsymbol{\beta}$: parámetros del modelo


## Forma final del estimador

$$
\hat{P}_d = \frac{\sum_{U_d} \hat{y}_{di}}{N_d}
$$

* Integra **observados y predicciones modeladas** para estimar la proporción total.


## Inferencia Bayesiana con Bernoulli


::: {.callout-tip}
### Datos
```{r, message=FALSE, echo=TRUE, warning=FALSE}
library(tidyverse)
set_data <- readRDS("data/encuesta2017CHL.Rds") %>% 
  mutate(etnia_ee = haven::as_factor(etnia_ee,levels = "values"))
n <- sum(set_data$etnia_ee == 1)
```
:::

* Filtrado por etnia: `Indígena` ($n = `r n`$)


* Variable: ingreso < línea de pobreza

$$
Y_i =
\begin{cases}
1 & \text{si ingreso < lp} \\
0 & \text{si ingreso ≥ lp}
\end{cases}
$$

## Inferencia Bayesiana con Bernoulli 

::: {.callout-tip}
### Preparando datos
```{r, message=FALSE, echo=TRUE, warning=FALSE}
datay <- set_data %>% filter(etnia_ee == 1) %>% 
  transmute(y = ifelse(ingcorte < lp, 1,0))
n = length(datay$y)
n1 = sum(datay$y)
addmargins(table(datay$y))
```
:::



## Distribuciones previa y posterior 

### Distribución previa

$$
\theta \sim Beta(\alpha=1, \beta=1)
$$

### Distribución posterior

$$
\theta \mid Y \sim Beta(\alpha + n_1, \beta + n_0)
$$


```{r, BernoEj0, echo = FALSE, fig.cap="Distribución previa (línea roja) y distribución posterior (línea negra)", eval=FALSE}
library(patchwork)
previa1 <- function(x) dbeta(x, 1, 1)
posterior1 <- function(x, y, a = 1, b = 1){
  n = length(y)
  n1 = sum(y)
  dbeta(x, shape1 = a + n1, 
           shape2 = b - n1 + n)
}
  

p1 <- ggplot(data = data.frame(x = 0),
             mapping = aes(x = x)) + ylab("f(x)") +
  stat_function(fun = previa1, color = "red", linewidth = 1.5)+
  stat_function(fun = posterior1,
                linewidth = 1.5, args = list(y = datay$y)) +
  theme(legend.position = "none") + 
  xlim(0.1,.2) + theme_bw(20) + 
  labs(x = latex2exp::TeX("\\theta"))

ggsave(plot = p1, filename = "img/Bernoulli/Bernoulli1.png")

```




```{r, BernoEj1, echo = FALSE, fig.cap="Distribución previa (línea roja) y distribución posterior (línea negra)", eval=TRUE}
knitr::include_graphics("img/Bernoulli/Bernoulli1.png")
```

## Estimación de $\theta$

La estimación del parámetro estaría dado por:

$$
E(X) = \frac{\alpha}{\alpha + \beta} = \frac{`r n1+1`}{`r n1+1`+ `r 1 - n1+ n`} = `r (n1+1)/( (n1+1) + (1 - n1+ n))`
$$

* IC 95%: `r round(qbeta(c(0.025, 0.975),shape1 = 1 + n1, shape2 = 1 - n1 + n),3)`



## Inferencia Bayesiana con STAN

::: {.callout-important}
### Modelo STAN (Bernoulli-Beta)

```{r}
Bernoulli_stan <- 
"data {
  int<lower=0> n;
  int y[n];
  real a; real b;
}
parameters { real<lower=0,upper=1> theta; }
model {
  y ~ bernoulli(theta);
  theta ~ beta(a,b);
}
generated quantities {
  real ypred[n];
  for(ii in 1:n) ypred[ii] = bernoulli_rng(theta);
}"
```
:::

## Ejecutar en R:
::: {.callout-note}
### Código en R
```{r, eval=FALSE}
library(rstan)
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE) # speed up running time 

sample_data <- list(
  n = nrow(datay), y = datay$y, a = 1, b = 1 )
model_Bernoulli <-
  stan( model_code = Bernoulli_stan, data = sample_data,
    iter = 1000, warmup = 500,  chains = 4, cores = 4,
     verbose = FALSE,
  )
saveRDS(model_Bernoulli, "img/Bernoulli/model_Bernoulli.rds")
summary(model_Bernoulli, pars = "theta")$summary
```
::: 

* Estimación: media posterior de $\theta$
* IC 95%: intervalos de credibilidad de la posterior

```{r, model_Bernoulli, eval=TRUE, echo=FALSE}
model_Bernoulli <- readRDS("img/Bernoulli/model_Bernoulli.rds")
summary(model_Bernoulli, pars = "theta")$summary %>% as.data.frame() %>% tba()
```

## Evaluación MCMC

- Distribución por cadena (densidad y áreas).

- Traceplot para verificar convergencia.

```{r, eval=FALSE, echo=FALSE}
library(bayesplot)
library(patchwork)
posterior_theta <- as.array(model_Bernoulli, pars = "theta")
p1 <- (mcmc_dens_chains(posterior_theta) +
    mcmc_areas(posterior_theta) ) / 
traceplot(model_Bernoulli,pars = "theta", inc_warmup = TRUE) 

ggsave(plot = p1,
       filename = "img/Bernoulli/Bernoulli3.png", scale = 2)
p1  
```


```{r echo=FALSE, out.width="200%", fig.align='center'}
knitr::include_graphics("img/Bernoulli/Bernoulli3.png")
```

## Predicción de $Y$

* Para cada iteración de la cadena se generan valores simulados $y^{pred}$.
* Se comparan contra los observados para validar ajuste.

```{r, eval=FALSE, echo=FALSE}
y_pred_B <- as.array(model_Bernoulli, pars = "ypred") %>% 
  as_draws_matrix()

rowsrandom <- sample(nrow(y_pred_B), 100)
y_pred2 <- y_pred_B[rowsrandom, 1:n]
p1 <- ppc_dens_overlay(y = datay$y, y_pred2)
ggsave(plot = p1,
       filename = "img/Bernoulli/Bernoulli4.png", scale = 2)
p1 
```

```{r echo=FALSE, , out.width="200%", fig.align='center'}
knitr::include_graphics("img/Bernoulli/Bernoulli4.png")
```

# Modelo de área: Binomial

## Modelo de área: Binomial

Cuando se dispone de una muestra aleatoria de variables con distribución Bernoulli $Y_1,\ldots,Y_n$, la inferencia Bayesiana se puede llevar a cabo usando la distribución Binomial.  
Es bien sabido que la suma de variables Bernoulli sigue una distribución Binomial:

$$
S=\sum_{i=1}^n Y_i \sim Binomial(n,\theta)
$$

La función de probabilidad es:

$$
p(S \mid \theta)=\binom{n}{s}\theta^s(1-\theta)^{n-s}I_{\{0,1,\ldots,n\}}(s)
$$

Cuando $n=1$, la Binomial se convierte en Bernoulli.  


## Teoría


Dado que $\theta$ es una proporción, la distribución natural es la **Beta**:

$$
p(\theta \mid \alpha,\beta)=
\frac{1}{Beta(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}I_{[0,1]}(\theta)
$$

La distribución posterior es:

$$
\theta \mid S \sim Beta(s+\alpha,\ \beta-s+n)
$$



## Extensión a múltiples dominios

Para $S_1,\ldots,S_D \sim Binomial(n_d,\theta_d)$ independientes, se tiene:

$$
\theta_d \mid s_d \sim Beta\left(s_d+\alpha,\ \beta+n_d-s_d\right)
$$

### Objetivo {-}

Estimar la proporción de personas que están por debajo de la línea de pobreza:

$$
P_{d}=\frac{\sum_{U}y_{di}}{N_{d}}
$$

Un estimador directo basado en el diseño muestral es:

$$
\hat{P}^{DIR}_{d} = \frac{\sum_{s_{d}}w_{di}y_{di}}{\sum_{s_{d}}w_{di}}
$$

donde $w_{di}$ es el factor de expansión del $i$-ésimo individuo en el dominio $d$.  

## Extensión a múltiples dominios

Asumimos entonces:

$$
P_{d}\mid \hat{P}^{DIR}_{d} \sim Beta(\alpha,\beta)
$$

El estimador Bayesiano es:

$$
\tilde{P}_{d} = E\!\left(P_{d}\mid \hat{P}^{DIR}_{d}\right)
$$


## Práctica en **R y STAN**

::: {.callout-tip}
### Código en R
```{r, message=FALSE, warning=FALSE, eval=TRUE}
dataS <- set_data %>% 
  transmute(
    dam = dam_ee,
    y = ifelse(ingcorte < lp, 1,0)
  ) %>% 
  group_by(dam) %>% 
  summarise(
    nd = n(),   # Número de ensayos 
    Sd = sum(y) # Número de éxitos
  )
```
:::

```{r, echo=FALSE}
dataS %>% head() %>% tba()
```

## Código en STAN

::: {.callout-important}
### Modelo binomial 

```{r, eval=FALSE}
Binomial_stan <-
"data {
  int<lower=0> K;     // Número de provincias
  int<lower=0> n[K];  // Número de ensayos 
  int<lower=0> s[K];  // Número de éxitos
  real a;
  real b;
}
parameters {
  real<lower=0, upper=1> theta[K]; 
}
model {
  for (kk in 1:K) {
    s[kk] ~ binomial(n[kk], theta[kk]);
  }
  to_vector(theta) ~ beta(a, b);
}
generated quantities {
  real spred[K];
  for (kk in 1:K){
    spred[kk] = binomial_rng(n[kk], theta[kk]);
  }
}"

```

:::

## Preparación de datos

::: {.callout-tip}
### Código en R

```{r, eval=FALSE}
sample_data <- list(
  K = nrow(dataS),
  s = dataS$Sd,
  n = dataS$nd,
  a = 1,
  b = 1
)
```
:::

## Compilando el modelo

::: {.callout-tip}
### Código en R

```{r, eval=FALSE}
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)

model_Binomial2 <- stan(
  model_code = Binomial_stan,
  data = sample_data,
  warmup = 500,
  iter = 1000,
  chains = 4,
  cores = 4
)
saveRDS(model_Binomial2, "img/Bernoulli/model_Binomial.rds")
```

:::

## Resultados

La estimación de $\theta$:

::: {.callout-tip}
### Código en R

```{r, eval=TRUE}
model_Binomial2 <- readRDS("img/Bernoulli/model_Binomial.rds")
tabla_Bin1 <- summary(model_Binomial2, pars = "theta")$summary
```
:::

```{r, eval=TRUE, echo=FALSE}
tabla_Bin1 %>% as.data.frame() %>% slice(1:5) %>% tba()
```



## Validación de cadenas con `bayesplot`:

```{r, eval=FALSE, echo=FALSE}
p1 <- mcmc_areas(as.array(model_Binomial2, pars = "theta"))
ggsave(plot = p1,
       filename = "img/Bernoulli/Binomial1.png", scale = 2)
p1  
```


```{r echo=FALSE, out.width="150%", fig.align='center'}
knitr::include_graphics("img/Bernoulli/Binomial1.png")
```



## Predicción de $S$

```{r, eval=FALSE, echo=FALSE}
y_pred_B <- as.array(model_Binomial2, pars = "spred") %>% 
  as_draws_matrix()

rowsrandom <- sample(nrow(y_pred_B), 200)
y_pred2 <- y_pred_B[rowsrandom, ]
g2 <- ppc_dens_overlay(y = dataS$Sd, y_pred2) 
p1 <- g2
ggsave(plot = p1,
       filename = "img/Bernoulli/Binomial3.png",
       scale = 2)
```


```{r echo=FALSE, out.width="150%" , fig.align='center'}
knitr::include_graphics("img/Bernoulli/Binomial3.png")
```

# Modelos de Unidad

## Introducción

- Los modelos de unidad son una de las aproximaciones más detalladas en SAE.  

- Operan a nivel *micro*, considerando cada hogar o persona como unidad.  

- Permiten capturar la heterogeneidad intra-área, mejorando la precisión de las estimaciones.  

## Formulación General

Formalmente, el modelo básico se expresa como:

$$
y_{ij} = x_{ij}^\top \beta + u_j + e_{ij}
$$

donde:

- $y_{ij}$: variable de interés de la unidad $i$ en el dominio $j$,

- $x_{ij}$: vector de covariables auxiliares a nivel de unidad,

- $u_j$: efecto aleatorio del dominio (común a las unidades del mismo área),

- $e_{ij}$: error aleatorio específico de la unidad.


## Supuestos del Modelo de Unidad

1. **Linealidad:** la relación entre $y_{ij}$ y $x_{ij}$ es lineal en los parámetros $\beta$.  

2. **Efectos de dominio:** $u_j \sim \text{iid } N(0, \sigma_u^2)$.  

3. **Errores individuales:** $e_{ij} \sim \text{iid } N(0, \sigma_e^2)$.  

4. **Independencia:** $u_j$ y $e_{ij}$ son independientes.  

5. **Homocedasticidad:** $\sigma_u^2$ y $\sigma_e^2$ son constantes entre áreas y unidades.  

6. **Información auxiliar:** las covariables $x_{ij}$ están disponibles para muestra y población, y medidas sin error.  

7. **Muestreo ignorable:** el mecanismo de selección muestral no introduce sesgo condicionalmente a $x_{ij}$.


## Características Principales

- Modelo jerárquico lineal con errores compuestos.  

- Estimación mediante **REML** o métodos bayesianos empíricos.  

- Predicción por dominio usando el **EBLUP** @battese1988.  

- Requiere información auxiliar (censos, registros administrativos).  



## Modelo de unidad: Normal con media desconocida


Suponga que $Y_1,\cdots,Y_n \sim Normal(\theta,\sigma^2)$ con $\theta$ desconocido y $\sigma^2$ conocido.  
La verosimilitud es:

$$
p(\mathbf{Y} \mid \theta)
=(2\pi\sigma^2)^{-n/2}\exp\left\{-\tfrac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\theta)^2\right\}
$$

Si $\theta \sim Normal(\mu,\tau^2)$, la distribución posterior es:

$$
\theta \mid \mathbf{Y} \sim Normal(\mu_n,\tau_n^2)
$$

con  

$$
\mu_n=\frac{\tfrac{n}{\sigma^2}\bar{Y}+\tfrac{1}{\tau^2}\mu}{\tfrac{n}{\sigma^2}+\tfrac{1}{\tau^2}},
\qquad
\tau_n^2=\left(\tfrac{n}{\sigma^2}+\tfrac{1}{\tau^2}\right)^{-1}
$$

## Objetivo {-}

Estimar el ingreso medio de las personas:

$$
\bar{Y}_d = \frac{\sum_{U_d}y_{di}}{N_d}
$$

El estimador es:

$$
\hat{\bar{Y}}_d = \frac{\sum_{s_d}y_{di} + \sum_{s^c_d}\hat{y}_{di}}{N_d},
\qquad
\hat{y}_{di}=E_{\mathscr{M}}(y_{di}\mid \mathbf{x}_d,\boldsymbol{\beta})
$$

Finalmente:

$$
\hat{\bar{Y}}_d = \frac{\sum_{U_d}\hat{y}_{di}}{N_d}
$$

## Práctica en **R y STAN**

::: {.callout-tip}
### Código en R

```{r,,echo=TRUE,fig.cap="Resultado en la muestra (azul) y distribución teórica (negra)", eval=FALSE}
dataNormal <- set_data %>%
   filter(dam_ee == 1, ingcorte>0) %>% 
   transmute(dam_ee, logIngreso = log(ingcorte+1)) 

media <- mean(dataNormal$logIngreso)
Sd <- sd(dataNormal$logIngreso)

g1 <- ggplot(dataNormal,aes(x = logIngreso))+ 
  geom_density(size=2, color="blue") +
  stat_function(fun=dnorm, args=list(mean=media, sd=Sd), size=2) +
  theme_bw(20) + labs(y="", x="Log(Ingreso)")

g2 <- ggplot(dataNormal,aes(sample=logIngreso))+
  stat_qq() + stat_qq_line() +
  theme_bw(20) 

p1 <- g1|g2
ggsave(plot = p1,
       filename = "Img/Normal/Normal1.png",
       scale = 2)
p1
```
:::

## Densidad del ingreso 

```{r, fig.cap="Resultado en la muestra (azul) y distribución teórica (negra)", eval=TRUE, echo=FALSE, out.width="150%" }
knitr::include_graphics("Img/Normal/Normal1.png")
```



## Código en STAN

::: {.callout-important}

### Modelo Stan normal con media desconocida

```{r}
NormalMedia_stan <-
"data {
  int<lower=0> n;         // Número de observaciones
  real y[n];              // LogIngreso 
  real<lower=0> Sigma;    // Desviación estándar
}
parameters {
  real theta;             // Media
}
model {
  y ~ normal(theta, Sigma);
  theta ~ normal(0, 1000);   // Prior
}
generated quantities {
  real ypred[n];
  for (kk in 1:n) {
    ypred[kk] = normal_rng(theta, Sigma);
  }
}"
```

:::

## Preparación y ejecución en R

::: {.callout-tip}

### Código en R

```{r, eval=FALSE}
sample_data <- list(
  n = nrow(dataNormal),
  Sigma = sd(dataNormal$logIngreso),
  y = dataNormal$logIngreso
)

model_NormalMedia <- stan(
  model_code = NormalMedia_stan,  data = sample_data,
  warmup = 500, iter = 1000,  chains = 4,   cores = 4
)
saveRDS(model_NormalMedia, "Img/Normal/model_NormalMedia.rds")
```

```{r, eval=TRUE, echo=FALSE}
model_NormalMedia <- 
  readRDS("Img/Normal/model_NormalMedia.rds")
```

:::

## Resultados

Estimación de $\theta$:

::: {.callout-tip}

### Código en R

```{r, eval=TRUE}
tabla_Nor1 <- summary(model_NormalMedia, pars = "theta")$summary
```
:::

```{r, eval=TRUE, echo=FALSE}
tabla_Nor1 %>% tba()
```


## Evaluación MCMC

```{r, eval=FALSE, echo=FALSE}
posterior_theta <- as.array(model_NormalMedia, pars="theta")
p1 <- (mcmc_dens_chains(posterior_theta) +
       mcmc_areas(posterior_theta)) /
       mcmc_trace(posterior_theta)

ggsave(plot = p1,
       filename ="Img/Normal/Normal2.png",
       scale = 2)
p1
```


```{r echo=FALSE, out.width="100%"}
knitr::include_graphics("Img/Normal/Normal2.png")
```



## Chequeo predictivo posterior:


```{r, eval=FALSE, echo=FALSE}
y_pred_B <- as.array(model_NormalMedia, pars = "ypred") %>%
  as_draws_matrix()
rowsrandom <- sample(nrow(y_pred_B), 200)
y_pred2 <- y_pred_B[rowsrandom,]
y_obs <- as.numeric(dataNormal$logIngreso)

p1 <- ppc_dens_overlay(y = y_obs, y_pred2) /
  ppc_dens_overlay(y = exp(y_obs) - 1, exp(y_pred2) - 1) + xlim(0, 2000000)

ggsave(plot = p1,
       filename = "Img/Normal/Normal3.png",
       scale = 2)

```

```{r echo=FALSE, out.width="100%"}
knitr::include_graphics("Img/Normal/Normal3.png")
```



## Modelos multiparamétricos

Cuando se tienen variables $Y_1,\ldots,Y_n \sim N(\theta, \sigma^2)$ y se desconocen tanto la media como la varianza, es necesario definir distribuciones previas adecuadas. Las opciones principales son:

* Asumir **independencia** entre $p(\theta)$ y $p(\sigma^2)$, ambas informativas.
* Asumir **independencia** entre $p(\theta)$ y $p(\sigma^2)$, ambas no informativas.
* Definir $p(\theta \mid \sigma^2)$ dependiente y $p(\sigma^2)$ independiente.



## Normal con media y varianza desconocida

Supongamos:  
$$
Y_i \sim N(\theta, \sigma^2), \quad i=1,\dots,n
$$


### Priors consideradas


$$\theta \sim Normal(0,10000)$$  
$$\sigma^2 \sim IG(0.0001,0.0001)$$  

Posterior condicional:  
$$
\theta \mid \sigma^2,\mathbf{Y} \sim Normal(\mu_n, \tau_n^2)
$$


## Objetivo


* **Meta:** Estimar el ingreso medio poblacional

$$
  \bar{Y}_d = \frac{\sum_{U_d} y_{di}}{N_d}
$$

* **Idea clave:** separar muestra $s_d$ y no muestra $s^c_d$

* **Estimador:**

$$
  \hat{\bar{Y}}_d = \frac{\sum_{s_d} y_{di} + \sum_{s^c_d} \hat{y}_{di}}{N_d}
$$

* **Predicciones:**

$$
\hat{y}_{di} = E_{\mathscr{M}}(y_{di} \mid \mathbf{x}_d, \boldsymbol{\beta})
$$


## Implementación en STAN

::: {.callout-important}

###  Modelo Stan multiparamétrico

```{r}
NormalMeanVar_stan <-
"data {
  int<lower=0> n;
  real y[n];
}
parameters {
  real theta;
  real sigma;
}
transformed parameters {
  real sigma2 = pow(sigma, 2);
}
model {
  y ~ normal(theta, sigma);
  theta ~ normal(0, 1000);
  sigma2 ~ inv_gamma(0.001, 0.001);
}
generated quantities {
  real ypred[n];
  for (kk in 1:n) ypred[kk] = normal_rng(theta, sigma);
}
"
```
:::

## Preparación y ejecución en R

::: {.callout-tip}

### Código en R

```{r, eval = FALSE, message=FALSE}
sample_data <- list(n = nrow(dataNormal),
                    y = dataNormal$logIngreso)
model_NormalMedia <- stan(
  model_code = NormalMeanVar_stan,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)

saveRDS(model_NormalMedia,"Img/Normal/model_NormalMedia2.rds")
```


```{r, eval = TRUE, echo=FALSE,message=FALSE}
model_NormalMedia <- 
  readRDS("Img/Normal/model_NormalMedia2.rds")
```
:::

## Resultados: posterior de $\theta$,  $\sigma^2$ y $\sigma$

::: {.callout-tip}

### Código en R

```{r, eval=TRUE}
tabla_Nor2 <- summary(model_NormalMedia, 
        pars = c("theta", "sigma2", "sigma"))$summary
```
:::

```{r, eval=TRUE, echo=FALSE}
tabla_Nor2 %>% tba()
```


## Resultados: posterior de $\theta$

```{r,eval=FALSE, echo=FALSE}
posterior_theta <- as.array(model_NormalMedia, pars = "theta")
p1 <- (mcmc_dens_chains(posterior_theta) +
    mcmc_areas(posterior_theta) ) / 
  mcmc_trace(posterior_theta)
ggsave(plot = p1,
       filename = "Img/Normal/Normal4.png",
       scale = 2)
p1 
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Normal/Normal4.png")
```

## Resultados: posterior de $\sigma^2$
```{r,eval=FALSE, echo=FALSE}
posterior_sigma2 <- as.array(model_NormalMedia, pars = "sigma2")
p1 <- (mcmc_dens_chains(posterior_sigma2) +
    mcmc_areas(posterior_sigma2) ) / 
  mcmc_trace(posterior_sigma2)
ggsave(plot = p1,
       filename = "Img/Normal/Normal5.png",
       scale = 2)
p1
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Normal/Normal5.png")
```

## Resultados: posterior de $\sigma$
```{r,eval=FALSE, echo=FALSE}
posterior_sigma <- as.array(model_NormalMedia, pars = "sigma")
p1 <- (mcmc_dens_chains(posterior_sigma) +
    mcmc_areas(posterior_sigma) ) / 
  mcmc_trace(posterior_sigma)
ggsave(plot = p1,
       filename = "Img/Normal/Normal6.png",
       scale = 2)
p1
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Normal/Normal6.png")
```

## Chequeo predictivo posterior:

```{r,eval=FALSE, echo=FALSE}
y_pred_B <- as.array(model_NormalMedia, pars = "ypred") %>% 
  as_draws_matrix()
rowsrandom <- sample(nrow(y_pred_B), 100)
y_pred2 <- y_pred_B[rowsrandom, ]

p1 <- ppc_dens_overlay(y = y_obs, y_pred2) /
  ppc_dens_overlay(y = exp(y_obs) - 1, exp(y_pred2) - 1) + xlim(0, 2000000)

ggsave(plot = p1,
       filename = "Img/Normal/Normal7.png",
       scale = 2)

```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Normal/Normal7.png")
```


## Modelo de área: Multinomial

* **Definición:**
  $\mathbf{Y}=(Y_1,\ldots,Y_K)$ con

$$
  p(\mathbf{Y}|\boldsymbol{\theta})=\binom{n}{y_1,\ldots,y_K}\prod_{k=1}^K \theta_k^{y_k}
$$

  sujeto a $\sum y_k=n,\;\; \sum \theta_k=1$.

* **Priors:**

$$\boldsymbol{\theta} \sim Dirichlet(\alpha_1,\ldots,\alpha_K)$$.

* **Posterior:**

$$\boldsymbol{\theta}|\mathbf{Y} \sim Dirichlet(y_1+\alpha_1,\ldots,y_K+\alpha_K)$$.


## Ejemplo aplicado

* Variable: **condición de actividad laboral**

  * 1 = Ocupado
  * 2 = Desocupado
  * 3 = Inactivo

* Estimación de interés: **tasa de desocupación**

$$
  \delta = \frac{\theta_2}{\theta_1 + \theta_2}
$$


### Visualización de resultados

* Estimaciones posteriores para:

  * $\theta_1, \theta_2, \theta_3$
  * $\delta$ (tasa de desocupación)



## Preparación y ejecución en R

Sea $Y$ condición de actividad laboral

```{r, eval=TRUE, echo=FALSE}
dataMult <- set_data %>%
  transmute(
   empleo = as.character(haven::as_factor(condact3))) %>% 
   filter(empleo %in% c("Desocupado", "Inactivo", "Ocupado")) %>% 
  group_by(empleo) %>%  tally() %>% 
  mutate(theta = n/sum(n))

dataMult %>% tba()

```



## Código en STAN

::: {.callout-important}

### Modelo multinomial en Stan

```{r, eval=FALSE }
Multinom_stan  <- 
"data {
  int<lower=0> k;  // Número de cátegoria 
  int y[k];        // Número de exitos 
  vector[k] alpha; // Parámetro de las distribción previa 
}
parameters {
  simplex[k] theta;
}
transformed parameters {
  real delta;                              // Tasa de desocupación
  delta = theta[2]/ (theta[2] + theta[1]); // (Desocupado)/(Desocupado + Ocupado)
}
model {
  y ~ multinomial(theta);
  theta ~ dirichlet(alpha);
}
generated quantities {
  int ypred[k];
  ypred = multinomial_rng(theta, sum(y));
}"

```
:::


## Preparando el código de `STAN`

::: {.callout-tip}

### Código en R 

```{r, eval=FALSE}
sample_data <- list(k = nrow(dataMult),
                    y = dataMult$n,
                    alpha = c(0.5, 0.5, 0.5))

model_Multinom <- stan(
  model_code =  Multinom_stan,   data = sample_data,   
  verbose = FALSE, warmup = 500, iter = 1000,            
  cores = 4              
)
saveRDS(model_Multinom, "Img/Multinomial/model_Multinom.rds")
```


```{r, eval=TRUE, echo=FALSE}
model_Multinom <- readRDS("Img/Multinomial/model_Multinom.rds")
```
:::


## La estimación del parámetro $\theta$ y $\delta$ es:

- **Desocupado** ($\theta_1$) , 
- **Inactivo** ($\theta_2$) y 
- **Ocupado** ($\theta_3$). 

```{r, eval=TRUE, echo=FALSE}
tabla_Mul1 <- summary(model_Multinom, pars = c("delta", "theta"))$summary %>% 
  as.data.frame()
tabla_Mul1 %>% tba()
```


## Resultados: posterior de $\theta_1$

```{r, eval=FALSE, echo=FALSE}
posterior_theta1 <- as.array(model_Multinom, pars = "theta[1]")
p1 <- (mcmc_dens_chains(posterior_theta1) +
    mcmc_areas(posterior_theta1) ) / 
  mcmc_trace(posterior_theta1)

ggsave(plot = p1,
       filename = "Img/Multinomial/Multinomial1.png",
       scale = 2)

```


```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Multinomial/Multinomial1.png")
```

## Resultados: posterior de $\theta_2$
```{r, eval=FALSE, echo=FALSE}
posterior_theta2 <- as.array(model_Multinom, pars = "theta[2]")
p1 <- (mcmc_dens_chains(posterior_theta2) +
    mcmc_areas(posterior_theta2) ) / 
  mcmc_trace(posterior_theta2)
ggsave(plot = p1,
       filename = "Img/Multinomial/Multinomial2.png",
       scale = 2)
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Multinomial/Multinomial2.png")
```

## Resultados: posterior de $\theta_3$

```{r, eval=FALSE, echo=FALSE}
posterior_theta3 <- as.array(model_Multinom, pars = "theta[3]")
p1 <- (mcmc_dens_chains(posterior_theta3) +
    mcmc_areas(posterior_theta3) ) / 
  mcmc_trace(posterior_theta3)
ggsave(plot = p1,
       filename = "Img/Multinomial/Multinomial3.png",
       scale = 2)
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Multinomial/Multinomial3.png")
```

## Resultados: posterior de $\delta$

```{r, eval=FALSE, echo=FALSE}
posterior_delta <- as.array(model_Multinom, pars = "delta")
p1 <-(mcmc_dens_chains(posterior_delta) +
    mcmc_areas(posterior_delta) ) / 
  mcmc_trace(posterior_delta)

ggsave(plot = p1,
       filename = "Img/Multinomial/Multinomial4.png",
       scale = 2)

```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("Img/Multinomial/Multinomial4.png")
```

## Chequeo predictivo posterior:

```{r,out.width = "500px", out.height="250px",fig.align='center', eval=FALSE, echo=FALSE}
n <- nrow(dataMult)
y_pred_B <- as.array(model_Multinom, pars = "ypred") %>% 
  as_draws_matrix()

rowsrandom <- sample(nrow(y_pred_B), 100)
y_pred2 <- y_pred_B[, 1:n]
p1 <- ppc_dens_overlay(y = as.numeric(dataMult$n), y_pred2)
ggsave(plot = p1,
       filename = "Img/Multinomial/ppc_multinomial.PNG",
       scale = 2)
```

```{r, echo = FALSE, fig.align='center', eval=TRUE}
knitr::include_graphics("Img/Multinomial/ppc_multinomial.PNG")
```




# ¡Gracias! 

# Referencias 