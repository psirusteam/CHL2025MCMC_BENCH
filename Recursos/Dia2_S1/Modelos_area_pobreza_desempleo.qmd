---
title: "Modelos de área"
subtitle: "Estimación de indicadores de pobreza y mercado laboral"
author: "Andrés Gutierrez y Stalyn Guerrero"
date: "`r Sys.Date()`"
format: 
  revealjs:
    theme: simple
    transition: fade
    slide-number: true
    toc: false
    css: styles.css
    width: 1500
    height: 1000
    margin: 0.1
    center: false
    navigationMode: linear
    controlsLayout: edges
    controlsTutorial: false
    hash: true
bibliography: references.bib
---

```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE
)

tba <- function(dat, cap = NA){
  kable(dat,
      format = "html", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = F)%>%
         kable_classic(full_width = F, html_font = "Arial Narrow")
}
library(rstan)
library(knitr)
library(kableExtra)
library(tidyverse)
library(magrittr)
library(bayesplot)
library(posterior)
library(patchwork)
```


## Introducción al modelo de Fay–Herriot

El modelo de @fay1979estimates es el modelo de área más utilizado en la estimación en áreas pequeñas.  

Su popularidad radica en que suele disponerse de información agregada por dominios (departamentos, municipios, provincias), más que de microdatos a nivel individual.  

Este modelo lineal mixto fue el primero en incorporar **efectos aleatorios a nivel de área**, permitiendo combinar la información muestral directa con covariables auxiliares externas.

$$
\theta_d = \boldsymbol{x}_d^{T}\boldsymbol{\beta} + u_d,\quad 
u_d \stackrel{ind}{\sim} (0,\sigma_u^2)
$$

## Modelo básico de estimación

Los verdaderos valores $\theta_d$ no son observables, por lo que se emplean estimadores directos:

$$
\hat{\theta}^{DIR}_d = \theta_d + e_d,\quad e_d \stackrel{ind}{\sim} (0,\sigma^2_{e_d})
$$

Sustituyendo en el modelo de Fay–Herriot se obtiene:

$$
\hat{\theta}^{DIR}_d = \boldsymbol{x}_d^{T}\boldsymbol{\beta} + u_d + e_d
$$

donde $\sigma^2_{e_d}$ representa la varianza del error de muestreo estimada a partir de la encuesta.



## Estimador BLUP bajo el modelo FH

El *mejor predictor lineal insesgado (BLUP)* de $\theta_d$ se define como:

$$
\tilde{\theta}^{FH}_d = \boldsymbol{x}_d^{T}\tilde{\boldsymbol{\beta}} + \tilde{u}_d,
\quad 
\tilde{u}_d = \gamma_d(\hat{\theta}^{DIR}_d - \boldsymbol{x}_d^{T}\tilde{\boldsymbol{\beta}})
$$

donde 

$$
\gamma_d = \frac{\sigma_u^2}{\sigma_u^2 + \sigma^2_{e_d}}
$$

El parámetro $\gamma_d$ actúa como *factor de ponderación*, reduciendo el sesgo de las estimaciones directas al incorporar información auxiliar.



## Aplicación al indicador de pobreza

Sea $P_d$ la probabilidad de que una persona esté en pobreza en el dominio $d$.  
El modelo de área se define como:

$$
\hat{P}^{DIR}_d = \boldsymbol{x}_d^{T}\boldsymbol{\beta} + u_d + e_d
$$

y se asume

$$
\hat{P}^{DIR}_d \mid u_d \sim N(\boldsymbol{x}_d^{T}\boldsymbol{\beta}+u_d, \sigma^2_{e_d}), \quad 
u_d \sim N(0, \sigma_u^2)
$$

El modelo puede estimarse bajo un enfoque **frecuentista o bayesiano**, asignando priors a $\boldsymbol{\beta}$ y $\sigma_u^2$:

$$
\beta_p \sim N(0,10000), \quad \sigma_u^2 \sim IG(0.0001, 0.0001)
$$



## Predictor bayesiano y forma cerrada

El *predictor óptimo* de $P_d$ es el valor esperado condicional:

$$
E(P_d|\hat{P}^{DIR}_d) = \gamma_d\hat{P}^{DIR}_d + (1-\gamma_d)\boldsymbol{x}_d^{T}\boldsymbol{\beta}
$$

con 
$$
\gamma_d = \frac{\sigma_u^2}{\sigma_u^2 + \sigma_{e_d}^2}
$$

Este predictor combina la estimación directa con la predicha por el modelo, reduciendo la varianza en dominios con tamaños muestrales pequeños.

## Interpretación 

- El modelo de Fay–Herriot permite obtener estimaciones más precisas en dominios pequeños.  

- La precisión depende de la relación entre la varianza del área ($\sigma_u^2$) y la varianza de muestreo ($\sigma_{e_d}^2$). 

- Un valor alto de $\gamma_d$ indica mayor confianza en los datos muestrales, mientras que uno bajo da más peso a las covariables auxiliares.  

- Es la base de los enfoques modernos de estimación bayesiana y multinivel en SAE (@rao2015).

# Estimación del modelo de área en `Stan` 

## Preparación del entorno

El procedimiento de estimación utiliza las librerías `tidyverse` y `magrittr` para la manipulación y transformación de datos.

El modelo se implementa bajo un enfoque bayesiano mediante `Stan`.

::: {.callout-tip}

### Código de `R`

```{r  message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
```
:::


## Lectura de datos base

Se cargan las estimaciones directas de pobreza y su varianza suavizada a nivel de dominio para el año 2017.
Luego, se seleccionan las variables relevantes: `dam2`, `nd`, `pobreza`, `vardir` y `hat_var`.

::: {.callout-tip}

### Código de `R`

```{r}
base_FH <- readRDS("data/pobreza/base_FH_2017.rds") %>% 
  select(dam2, nd, pobreza, vardir, hat_var)
head(base_FH) %>% tba()
```
:::

## Lectura y normalización de covariables

Se cargan los predictores auxiliares a nivel de dominio y se estandarizan para evitar problemas de escala.

::: {.callout-tip}

### Código de `R`

```{r}
statelevel_predictors_df <- readRDS("data/pobreza/statelevel_predictors_df_dam2.rds") %>% 
  mutate_at(.vars = c("luces_nocturnas",
                      "cubrimiento_cultivo",
                      "cubrimiento_urbano",
                      "modificacion_humana",
                      "accesibilidad_hospitales",
                      "accesibilidad_hosp_caminado"),
            function(x) as.numeric(scale(x)))
```
:::


## Unión de datos

Se realiza una unión completa entre las estimaciones directas y las covariables, utilizando `dam2` como clave.
Esto asegura que se mantengan todos los dominios, observados y no observados.

::: {.callout-tip}

### Código de `R`

```{r}
base_FH <- full_join(base_FH, statelevel_predictors_df, by = "dam2")
tba(base_FH[1:5,1:8])
```
:::


## División por dominios observados y no observados

Los dominios con información muestral (`pobreza` no nula) se separan de los dominios sin información (`NA`).

::: {.callout-tip}

### Código de `R`
```{r}
data_dir <- base_FH %>% filter(!is.na(pobreza))
data_syn <- base_FH %>% anti_join(data_dir %>% select(dam2))
tba(data_syn[1:10,1:8] %>% head())
```
:::

## Construcción de la matriz de covariables

Se define la fórmula del modelo lineal con las variables predictoras.

A partir de ella, se construyen las matrices de diseño `Xdat` (observados) y `Xs` (no observados).

::: {.callout-tip}

### Código de `R`
```{r}
formula_mod <- formula(~ sexo2 + anoest2 + anoest3 + anoest4 +
                        edad2 + edad3 + edad4 + edad5 +
                        etnia1 + etnia2 + tasa_desocupacion +
                        luces_nocturnas + cubrimiento_urbano +
                        pollution_CO + vegetation_NDVI +
                        Elevation + precipitation +
                        population_density + cubrimiento_cultivo +
                        alfabeta)

Xdat <- model.matrix(formula_mod, data = data_dir)
Xs   <- model.matrix(formula_mod, data = data_syn)
```
:::


## Alineación de matrices

Se identifican y agregan columnas faltantes a `Xs` para asegurar que ambas matrices tengan la misma estructura.

::: {.callout-tip}

### Código de `R`

```{r}
temp <- setdiff(colnames(Xdat), colnames(Xs))
temp <- matrix(0, nrow = nrow(Xs), ncol = length(temp), dimnames = list(1:nrow(Xs), temp))
Xs <- cbind(Xs, temp)[, colnames(Xdat)]
```
:::


## Preparación de la lista para Stan

Se crea la lista `sample_data`, que contiene toda la información necesaria para ejecutar el modelo en `Stan`.

::: {.callout-tip}

### Código de `R`

```{r}
sample_data <- list(
  N1 = nrow(Xdat),   
  N2 = nrow(Xs),   
  p  = ncol(Xdat),       
  X  = as.matrix(Xdat),  
  Xs = as.matrix(Xs),    
  y  = as.numeric(data_dir$pobreza), 
  sigma_e = sqrt(data_dir$hat_var)
)
```
:::


## Modelo en `Stan`: data

A continuación, se presenta la estructura del modelo de Fay–Herriot en el lenguaje de modelado probabilístico Stan.

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
data {
  int<lower=0> N1;   // number of data items
  int<lower=0> N2;   // number of data items for prediction
  int<lower=0> p;   // number of predictors
  matrix[N1, p] X;   // predictor matrix
  matrix[N2, p] Xs;   // predictor matrix
  vector[N1] y;      // predictor matrix 
  vector[N1] sigma_e; // known variances
}
```
:::

## Modelo en `Stan`: parameters

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
parameters {
  vector[p] beta;       // coefficients for predictors
  real<lower=0> sigma2_u;
  vector[N1] u;
}

transformed parameters{
  vector[N1] theta;
  vector[N1] thetaSyn;
  vector[N1] thetaFH;
  vector[N1] gammaj;
  real<lower=0> sigma_u;
  thetaSyn = X * beta;
  theta = thetaSyn + u;
  sigma_u = sqrt(sigma2_u);
  gammaj =  to_vector(sigma_u ./ (sigma_u + sigma_e));
  thetaFH = (gammaj) .* y + (1-gammaj).*thetaSyn; 
}
```
:::

## Modelo en `Stan`: model y generated

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
model {
  // likelihood
  y ~ normal(theta, sigma_e); 
  // priors
  beta ~ normal(0, 100);
  u ~ normal(0, sigma_u);
  sigma2_u ~ inv_gamma(0.0001, 0.0001);
}

generated quantities{
  vector[N2] y_pred;
  for(j in 1:N2) {
    y_pred[j] = normal_rng(Xs[j] * beta, sigma_u);
  }
}

```
:::


## Compilación del modelo en R

Se ajusta el modelo de Stan utilizando la función `stan()` de la librería `rstan`.
El modelo se guarda como objeto `.rds` para su posterior análisis.

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
library(rstan)
fit_FH_normal <- "data/pobreza/modelosStan/17FH_normal.stan"
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)

model_FH_normal <- stan(
  file = fit_FH_normal,  
  data = sample_data,
  warmup = 500, iter = 1000, cores = 4, verbose = FALSE
)

saveRDS(model_FH_normal, "data/pobreza/model_FH_normal.rds")
```
:::


## Lectura del modelo estimado

Para evitar recalcular el modelo, se puede cargar directamente el objeto ajustado.

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
model_FH_normal <- readRDS("data/pobreza/model_FH_normal.rds")
```
:::

##  Resultados del modelo para dominios observados

Se evalúa la capacidad predictiva del modelo mediante comparaciones gráficas entre la distribución empírica y las distribuciones predictivas posteriores de pobreza:


::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
library(bayesplot)
library(posterior)
library(patchwork)
y_pred_B <- as.array(model_FH_normal, pars = "theta") %>% 
  as_draws_matrix()
rowsrandom <- sample(nrow(y_pred_B), 100)
y_pred2 <- y_pred_B[rowsrandom, ]

p1 <- ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) +
  theme_light()

ggsave(filename = "data/img/FH1.png",plot = p1,scale = 2)

```
:::

## Comparación de densidades observadas y simuladas

Esta visualización compara la densidad observada $y$ con las densidades simuladas $\tilde{y}$ a partir de la distribución posterior, permitiendo identificar ajustes adecuados o desviaciones sistemáticas en la predicción.


```{r echo=FALSE, out.width="200%"}
knitr::include_graphics( "data/img/FH1.png")
```

## Análisis de convergencia

El análisis de convergencia de las cadenas de Markov se realiza sobre el parámetro de varianza de los efectos aleatorios, $\sigma^2_u$.

Se examinan los gráficos de densidad, áreas y trazas de MCMC:

::: {.callout-tip}

### Código de `R`
```{r, eval=FALSE}
posterior_sigma2_u <- as.array(model_FH_normal, pars = "sigma2_u")
p1 <- (mcmc_dens_chains(posterior_sigma2_u) +
    mcmc_areas(posterior_sigma2_u) ) / 
  mcmc_trace(posterior_sigma2_u)

ggsave(filename = "data/img/FH2.png",plot = p1, scale = 2)
```
:::

##  Convergencia de las cadenas de $\sigma^2_u$

Una convergencia adecuada se evidencia cuando las cadenas se mezclan bien y no presentan tendencias sistemáticas.

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img/FH2.png")
```

## Validación y comparación de estimaciones

Se comparan tres estimaciones de pobreza obtenidas del modelo:

- **$\theta_{\text{pred}}$:** estimación a partir del modelo FH.

- **$\theta_{\text{Syn}}$:** estimación sintética basada en el componente fijo.  

- **$\theta_{\text{FH}}$:** estimación combinada de Fay-Herriot.

$$
\text{Comparación: } (\theta_{\text{pred}}, \theta_{\text{FH}}), \; (\theta_{\text{Syn}}, \theta_{\text{FH}}), \; (\theta_{\text{dir}}, \theta_{\text{FH}})
$$

La coherencia entre estas estimaciones valida el buen desempeño del modelo en dominios observados.

## Estrayendo la cadenas para comparaciones gráficas entre estimaciones

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
theta <-   summary(model_FH_normal,pars =  "theta")$summary %>%
  data.frame()
thetaSyn <-   summary(model_FH_normal,pars =  "thetaSyn")$summary %>%
  data.frame()
theta_FH <-   summary(model_FH_normal,pars =  "thetaFH")$summary %>%
  data.frame()

data_dir %<>% mutate(
            thetadir = pobreza,
            theta_pred = theta$mean,
            thetaSyn = thetaSyn$mean,
            thetaFH = theta_FH$mean,
            theta_pred_EE = theta$sd,
            Cv_theta_pred = theta_pred_EE/theta_pred
            )
```
:::

## Comparaciones gráficas entre estimaciones

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
# Estimación predicción del modelo vs ecuación ponderada de FH 
p11 <- ggplot(data_dir, aes(x = theta_pred, y = thetaFH)) +
  geom_point() + 
  geom_abline(slope = 1,intercept = 0, colour = "red") +
  theme_bw(10) 

# Estimación con la ecuación ponderada de FH Vs estimación sintética
p12 <- ggplot(data_dir, aes(x = thetaSyn, y = thetaFH)) +
  geom_point() + 
  geom_abline(slope = 1,intercept = 0, colour = "red") +
  theme_bw(10) 

# Estimación con la ecuación ponderada de FH Vs estimación directa

p21 <- ggplot(data_dir, aes(x = thetadir, y = thetaFH)) +
  geom_point() + 
  geom_abline(slope = 1,intercept = 0, colour = "red") +
  theme_bw(10) 

# Estimación directa Vs estimación sintética

p22 <- ggplot(data_dir, aes(x = thetadir, y = thetaSyn)) +
  geom_point() + 
  geom_abline(slope = 1,intercept = 0, colour = "red") +
  theme_bw(10) 

p1 <- (p11+p12)/(p21+p22)
ggsave(filename = "data/img/FH3.png",plot = p1, scale = 2)

```
:::

## Comparaciones gráficas entre estimaciones

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img/FH3.png")
```



## Predicciones para dominios no observados y consolidación

A partir de las muestras posteriores de $y_{\text{pred}}$, se obtienen estimaciones de pobreza para los dominios sin información directa.  
Cada dominio no observado recibe una predicción $\hat{\theta}_d$ con su error estándar asociado.

$$
\text{Cv}_{\hat{\theta}_d} = \frac{\text{EE}(\hat{\theta}_d)}{\hat{\theta}_d}
$$


Estimación del FH de la pobreza en los dominios NO observados. 

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
theta_syn_pred <- summary(model_FH_normal,pars =  "y_pred")$summary %>%
  data.frame()

data_syn <- data_syn %>% 
  mutate(
    theta_pred = theta_syn_pred$mean,
    thetaSyn = theta_pred,
    thetaFH = theta_pred,
    theta_pred_EE = theta_syn_pred$sd,
    Cv_theta_pred = theta_pred_EE/theta_pred)

saveRDS(data_syn, "data/pobreza/data_syn.rds")
saveRDS(data_dir, "data/pobreza/data_dir.rds")


```

:::

## Predicciones para dominios no observados y consolidación


```{r, echo=FALSE}
data_syn <- readRDS("data/pobreza/data_syn.rds")
data_dir <- readRDS("data/pobreza/data_dir.rds")

tba(data_syn %>% slice(1:10) %>%
      select(dam2:hat_var,theta_pred:Cv_theta_pred))

```

## Consolidar las bases 

Finalmente, se consolidan las bases de estimaciones directas y sintéticas:

::: {.callout-tip}

### Código de `R`
```{r}
estimacionesPre <- bind_rows(data_dir, data_syn) %>% 
  select(dam2, estimacion_normal = theta_pred, 
         ee_normal = theta_pred_EE,
         cv_normal = Cv_theta_pred) %>% 
  mutate(dam = substr(dam2,1,2))

saveRDS(estimacionesPre, file = "data/pobreza/estimacionesPre_normal.rds")
```
:::

# Modelos de Área y Transformación Arcoseno


## Introducción

En su concepción más básica, el modelo de *Fay-Herriot normal* es una combinación lineal de covariables. El problema surge cuando el resultado de esta combinación puede salirse del rango $(0,1)$, propio de las proporciones. Para corregirlo, se aplica la **transformación arcoseno**:

$$
\hat{z}_d = arcsin\left( \sqrt{ \hat{\theta}_d} \right)
$$

donde la varianza del estimador transformado es:

$$
Var\left( \hat{z}_d \right) = \frac{1}{4\times n_{d,efectivo} }
$$

## Especificación del modelo

El modelo de Fay-Herriot transformado es:

$$
\begin{eqnarray*}
Z_d \mid \mu_d,\sigma^2_d &  \sim  & N(\mu_d, \sigma^2_d)\\
\mu_d & = & \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d \\
\theta_d & = &  \left(\sin(\mu_d)\right)^2
\end{eqnarray*}
$$

con $u_d \sim N(0, \sigma^2)$ y priors:

$$
\boldsymbol{\beta} \sim N(0,1000), \quad
\sigma_{u}^{2} \sim IG(0.0001,0.0001)
$$



## Modelo en `Stan`: data

A continuación, se presenta la estructura del modelo de Fay–Herriot con transformación arcoseno en el lenguaje de modelado probabilístico Stan.

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
data {
  int<lower=0> N1;     // number of data items
  int<lower=0> N2;     // number of data items for prediction
  int<lower=0> p;      // number of predictors
  matrix[N1, p] X;     // predictor matrix
  matrix[N2, p] Xs;    // predictor matrix
  vector[N1] y;        // predictor matrix 
  vector[N1] sigma_e;  // known variances
}

```
:::

## Modelo en `Stan`: parameters

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
parameters {
  vector[p] beta;       // coefficients for predictors
  real<lower=0> sigma2_u;
  vector[N1] u;
}

transformed parameters{
  vector[N1] theta;
  vector[N1] lp;
  real<lower=0> sigma_u;
  lp = X * beta + u;
  sigma_u = sqrt(sigma2_u);
  for(k in 1:N1){
    theta[k] = pow(sin(lp[k]), 2);
  }
}

```
:::

## Modelo en `Stan`: model y generated

::: {.callout-important}

### Código de `Stan`

```{r, eval=FALSE}
model {
  // likelihood
  y ~ normal(lp, sigma_e); 
  // priors
  beta ~ normal(0, 100);
  u ~ normal(0, sigma_u);
  sigma2_u ~ inv_gamma(0.0001, 0.0001);
}

generated quantities{
  vector[N2] theta_pred;
  vector[N2] lppred;
  for(j in 1:N2) {
    lppred[j] = normal_rng(Xs[j] * beta, sigma_u);
    theta_pred[j] = pow(sin(lppred[j]), 2);
  }
}

```
:::





## Preparación de datos

::: {.callout-tip}

### Lectura y transformación de la base

```{r}
base_FH <- readRDS("data/pobreza/base_FH_2017.rds") %>% 
  transmute(dam2,                            
            pobreza,
            T_pobreza = asin(sqrt(pobreza)),  
            n_effec = n_eff_FGV,              
            varhat = 1/(4*n_effec))           
```
:::

```{r, echo=FALSE}
head(base_FH) %>% tba()
```


## Lectura de las covariables

::: {.callout-tip}

### Código de `R`

```{r}
statelevel_predictors_df <- readRDS("data/pobreza/statelevel_predictors_df_dam2.rds") %>% 
    mutate_at(.vars = c("luces_nocturnas",
                      "cubrimiento_cultivo",
                      "cubrimiento_urbano",
                      "modificacion_humana",
                      "accesibilidad_hospitales",
                      "accesibilidad_hosp_caminado"),
            function(x) as.numeric(scale(x)))
```
:::


## Unión de bases

::: {.callout-tip}

### Código de `R`

```{r}
base_FH <- full_join(base_FH, statelevel_predictors_df, by = "dam2" )
```
:::


```{r, echo=FALSE}
tba(base_FH[,1:8] %>% head(10), cap = "Vista parcial de la base unificada")
```


# Selección de covariables

::: {.callout-tip}

### Código de `R`

```{r}
names_cov <- c(
  "sexo2" ,"anoest2" ,"anoest3","anoest4",
  "edad2" ,"edad3" ,"edad4" ,"edad5",
  "etnia1","etnia2","tasa_desocupacion",
  "luces_nocturnas","cubrimiento_cultivo",
  "alfabeta","pollution_CO","vegetation_NDVI",
  "Elevation","precipitation","population_density"
)
```
:::

::: {.callout-tip}

### División por tipo de dominio

```{r}
data_dir <- base_FH %>% filter(!is.na(T_pobreza))
data_syn <- base_FH %>% anti_join(data_dir %>% select(dam2))
```
:::

## Dominios no observados

```{r, echo=FALSE}
tba(data_syn[,1:8] %>% slice(1:10), cap = "Dominios no observados")
```


## Matrices de efectos fijos

::: {.callout-tip}

### Código de `R`

```{r}
Xdat <- cbind(inter = 1, data_dir[,names_cov])
Xs <- cbind(inter = 1, data_syn[,names_cov])
```
:::

```{r, echo=FALSE}
tba(head(Xdat, 5), cap = "Matrices de efectos fijos dominios observados")
```


## Lista de parámetros para STAN

::: {.callout-tip}

### Código de `R`

```{r}
sample_data <- list(
  N1 = nrow(Xdat),
  N2 = nrow(Xs),
  p  = ncol(Xdat),
  X  = as.matrix(Xdat),
  Xs = as.matrix(Xs),
  y  = as.numeric(data_dir$T_pobreza),
  sigma_e = sqrt(data_dir$varhat)
)
```
:::


# Compilación del modelo en STAN

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
library(rstan)
fit_FH_arcoseno <- "data/pobreza/modelosStan/15FH_arcsin_normal.stan"
options(mc.cores = parallel::detectCores())
rstan::rstan_options(auto_write = TRUE)

model_FH_arcoseno <- stan(
  file = fit_FH_arcoseno,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,
  iter = 1000,
  cores = 4
)
saveRDS(model_FH_arcoseno,
        "data/pobreza/model_FH_arcoseno.rds")
model_FH_arcoseno <- readRDS("data/pobreza/model_FH_arcoseno.rds")

```
:::



## Comparación entre datos observados y simulados

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
library(bayesplot)
library(posterior)
library(patchwork)

y_pred_B <- as.array(model_FH_arcoseno, pars = "theta") %>% 
  as_draws_matrix()
rowsrandom <- sample(nrow(y_pred_B), 100)

y_pred2 <- y_pred_B[rowsrandom, ]

p1 <- ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) + 
  theme_light()

ggsave(filename = "data/img/FH_Asin.png",plot = p1, scale = 2)

```
:::


## Comparación entre datos observados y simulados

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img//FH_Asin.png")
```

El gráfico permite comparar la distribución empírica de la pobreza observada con la distribución predictiva del modelo FH con transformación arcoseno.


## Análisis de convergencia

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
posterior_sigma2_u <- as.array(model_FH_arcoseno, pars = "sigma2_u")
p1 <- (mcmc_dens_chains(posterior_sigma2_u) +
    mcmc_areas(posterior_sigma2_u)) / 
  mcmc_trace(posterior_sigma2_u)

ggsave(filename = "data/img/FH_Asin2.png",plot = p1, scale = 2)

```
:::

## Análisis de convergencia $\sigma_u^2$

Las gráficas muestran buena mezcla y estabilidad de las cadenas, lo cual sugiere convergencia del modelo.


```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img/FH_Asin2.png")
```



## Dominios observados

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
theta_FH <- summary(model_FH_arcoseno, pars = "theta")$summary %>%
  data.frame()

data_dir %<>% mutate(
  pred_arcoseno = theta_FH$mean, 
  pred_arcoseno_EE = theta_FH$sd,
  Cv_pred = pred_arcoseno_EE/pred_arcoseno
)
```
:::


## Dominios no observados

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
theta_FH_pred <- summary(model_FH_arcoseno, pars = "theta_pred")$summary %>%
  data.frame()

data_syn <- data_syn %>% 
  mutate(pred_arcoseno = theta_FH_pred$mean,
         pred_arcoseno_EE = theta_FH_pred$sd,
         Cv_pred = pred_arcoseno_EE/pred_arcoseno)

data_arcoseno <- rbind(data_dir, data_syn) %>% 
  select(dam2, pobreza, 
         estimacion_arcoseno = pred_arcoseno,
         ee_arcoseno = pred_arcoseno_EE,
         cv_arcoseno = Cv_pred ) 

```
:::

## Comparando resultados de los modelos 

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
estimacion_pobreza <- inner_join(data_arcoseno, estimacionesPre) 
saveRDS(estimacion_pobreza, "data/pobreza/estimacion_pobreza.rds")
```
:::

```{r, eval=TRUE, echo=FALSE}
estimacion_pobreza <- readRDS("data/pobreza/estimacion_pobreza.rds")
tba(head(estimacion_pobreza %>% arrange(estimacion_normal),10))

```

## Comparación directa de estimaciones

```{r, echo=FALSE, eval=FALSE}
p1 <- ggplot(estimacion_pobreza, aes(x = estimacion_normal, y = estimacion_arcoseno)) +
  geom_point(color = "steelblue", size = 3, alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Comparación entre modelos: Normal vs Arcoseno",
    subtitle = "Cada punto representa un dominio",
    x = "Estimación FH Normal",
    y = "Estimación FH Arcoseno"
  ) +
  theme_minimal(base_size = 13)

ggsave(filename = "data/img/FH_vs_Asin.png",plot = p1, scale = 2)
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img/FH_vs_Asin.png")
```


## Comparación de coeficientes de variación (precisión)

```{r, echo=FALSE, eval=FALSE}
p1 <- ggplot(estimacion_pobreza, aes(x = abs(cv_normal), y = cv_arcoseno)) +
  geom_point(color = "darkgreen", size = 3, alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Comparación de precisión entre modelos",
    subtitle = "Coeficiente de variación (CV)",
    x = "CV - FH Normal",
    y = "CV - FH Arcoseno"
  ) +
  theme_minimal(base_size = 13)
ggsave(filename = "data/img/FH_vs_Asin2.png",plot = p1, scale = 2)
```


```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("data/img/FH_vs_Asin2.png")
```

# Conclusiones

* La **transformación arcoseno** garantiza que las estimaciones del modelo se mantengan en el rango $(0,1)$.

* El **modelo de Fay-Herriot** permite combinar información directa y auxiliar, mejorando la precisión en dominios pequeños.

* Las gráficas de densidad y convergencia sugieren que el ajuste fue adecuado y estable.

* Los resultados finales proveen estimaciones coherentes para dominios observados y no observados.

# Modelo de área para estadísticas del mercado de trabajo

## Introducción

La **Encuesta de Caracterización Socioeconómica Nacional (CASEN)**, ejecutada por el Instituto Nacional de Estadísticas (INE) de Chile, constituye una de las principales fuentes de información para el seguimiento de la situación social y económica del país.

Entre sus objetivos se encuentra la medición de indicadores del **mercado de trabajo**, tales como la **tasa de participación**, **ocupación** y **desempleo**.

Sin embargo, los estimadores directos derivados de la encuesta suelen presentar **alta variabilidad** en dominios pequeños (regiones, provincias, comunas), lo que motiva el uso de **modelos de área** para mejorar la precisión y estabilidad de las estimaciones.


## Indicadores del mercado de trabajo

Los indicadores que se modelan de manera conjunta son:

* $p_{1}$: Proporción de personas **ocupadas**.
* $p_{2}$: Proporción de personas **desocupadas**.
* $p_{3}$: Proporción de personas **inactivas**.

Dado que las tres categorías son mutuamente excluyentes y exhaustivas, el vector de probabilidades $\boldsymbol{\theta}_d = (p_{d1}, p_{d2}, p_{d3})'$ debe cumplir:

$$
\sum_{k=1}^{3} p_{dk} = 1
$$

# Definición del modelo multinomial

Sea $K$ el número de categorías de la variable de interés $Y \sim Multinomial(\boldsymbol{\theta})$, con $\boldsymbol{\theta} = (p_{1}, p_{2}, \dots , p_{K})$ y $\sum_{k=1}^{K}p_{k}=1$.

Para el dominio $d$:

* $N_d$: número total de personas.

* $N_{dk}$: número de personas en la categoría $k$.

* $\hat{p}_{dk} = N_{dk}/N_d$: estimación directa de la proporción.

* $\hat{v}_{dk} = \widehat{Var}(\hat{p}_{dk})$: varianza estimada.


## Tamaño muestral efectivo

Dado que el efecto de diseño varía entre categorías, se define un **tamaño muestral efectivo** por categoría:

$$
\tilde{n}_{dk} = \frac{\tilde{p}_{dk} \times (1 - \tilde{p}_{dk})}{\hat{v}_{dk}}
$$

De esta manera:

$$
\tilde{y}_{dk} = \tilde{n}_{dk} \times \hat{p}_{dk}, \quad
\hat{n}_i = \sum_{k=1}^{K} \tilde{y}_{dk}
$$

y se sigue que:

$$
\hat{y}_{dk} = \hat{n}_d \times \hat{p}_{dk}
$$

## Modelo de área propuesto

El modelo multinomial a nivel de dominio se expresa como:

$$
(\tilde{y}_{d1}, \tilde{y}_{d2}, \tilde{y}_{d3}) \mid \hat{n}_d, \boldsymbol{\theta}_d \sim Multinomial(\hat{n}_d, \boldsymbol{\theta}_d)
$$

donde las probabilidades $p_{dk}$ se relacionan con covariables observadas mediante modelos logísticos multinivel.


## Ecuaciones del modelo

Definiendo la categoría base como ocupado ($k=1$), se tiene:

$$
\ln\left(\frac{p_{d2}}{p_{d1}}\right) = \mathbf{X}_d^\top \boldsymbol{\beta_2} + u_{i2}
$$

$$
\ln\left(\frac{p_{d3}}{p_{d1}}\right) = \mathbf{X}_d^\top \boldsymbol{\beta_3} + u_{d3}
$$

donde $u_{ik}$ son efectos aleatorios de área, con:

$$
(u_{i2}, u_{i3})' \sim N(\mathbf{0}, \boldsymbol{\Sigma_u})
$$

## Restricciones y derivación

Usando la restricción $\sum_{k=1}^3 p_{dk} = 1$, se obtiene:

$$
p_{d1} = \frac{1}{1 + e^{\mathbf{X}_d^\top \boldsymbol{\beta_2} + u_{d2}} + e^{\mathbf{X}_d^\top \boldsymbol{\beta_3} + u_{d3}}}
$$

$$
p_{d2} = \frac{e^{\mathbf{X}_d^\top \boldsymbol{\beta_2} + u_{d2}}}{1 + e^{\mathbf{X}_d^\top \boldsymbol{\beta_2} + u_{d2}} + e^{\mathbf{X}_d^\top \boldsymbol{\beta_3} + u_{d3}}}
$$

$$
p_{d3} = \frac{e^{\mathbf{X}_d^\top \boldsymbol{\beta_3} + u_{d3}}}{1 + e^{\mathbf{X}_d^\top \boldsymbol{\beta_2} + u_{i2}} + e^{\mathbf{X}_d^\top \boldsymbol{\beta_3} + u_{d3}}}
$$


# Implementación del modelo en R

## Librerías,  configuración inicial y lectura de la encuesta

::: {.callout-tip}

### Código de `R`

```{r}
library(survey)
library(tidyverse)
library(srvyr)
library(TeachingSampling)
library(haven)
library(bayesplot)
library(patchwork)
library(stringr)
library(rstan)

set_data <- readRDS('Data/empleo/encuesta2017CHL.Rds')

length_upm <- max(nchar(set_data[["_upm"]]))
length_estrato <- max(nchar(set_data[["_estrato"]]))
id_dominio <- "dam2"
```
:::

## Selección de variables
::: {.callout-tip}

### Código de `R`

```{r}
set_data <- set_data %>%
  transmute(
    dam = as_factor(dam_ee, levels = "values"),
    dam = str_pad(string = dam, width = 2, pad = "0"),
    dam2 = as_factor(comuna, levels = "values"),
    dam2 = str_pad(string = dam2, width = 5, pad = "0"),
    nombre_dam = as_factor(dam_ee, levels = "labels"),
    nombre_dam2 = as_factor(comuna, levels = "labels"),
    upm = str_pad(`_upm`, width = length_upm, pad = "0"),
    estrato = str_pad(`_estrato`, width = length_estrato, pad = "0"),
    fep = `_fep`,
    empleo = condact3
  )
```
:::

## Definición del diseño muestral

::: {.callout-tip}

### Código de `R`

```{r}
options(survey.lonely.psu = 'adjust')

diseno <- set_data %>%
  as_survey_design(
    strata = estrato,
    ids = upm,
    weights = fep,
    nest = TRUE
  )
```
:::

## Estimaciones directas por dominio

Se calculan proporciones y estadísticas de empleo, desocupación e inactividad por dominio:

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
indicador_dam <- diseno %>%
  group_by_at(id_dominio) %>%
  filter(empleo %in% c(1:3)) %>%
  summarise(
    n_ocupado = unweighted(sum(empleo == 1)),
    n_desocupado = unweighted(sum(empleo == 2)),
    n_inactivo = unweighted(sum(empleo == 3)),
    Ocupado = survey_mean(empleo == 1, vartype = c("se", "var"), deff = TRUE),
    Desocupado = survey_mean(empleo == 2, vartype = c("se", "var"), deff = TRUE),
    Inactivo = survey_mean(empleo == 3, vartype = c("se", "var"), deff = TRUE)
  )
```
:::



## Selección de dominios válidos

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
indicador_dam <- set_data %>%
  select(id_dominio, upm) %>%
  distinct() %>%
  group_by_at(id_dominio) %>%
  tally(name = "n_upm") %>%
  inner_join(indicador_dam, by = id_dominio)

indicador_dam1 <- indicador_dam %>%
  filter(n_upm >= 2, !is.na(Desocupado_deff)) %>%
  mutate(id_orden = 1:n())

saveRDS(indicador_dam1, "data/empleo/base_modelo.Rds")
```
:::

## Tabla de resultados 

```{r, echo=FALSE}
indicador_dam1 <- readRDS("data/empleo/base_modelo.Rds")
tba(head(indicador_dam1, 10))
```

## Modelo multinomial jerárquico en `STAN`

* Variable respuesta por dominio: $Y_d = (\text{ocupado}, \text{desocupado}, \text{inactivo})$

* Distribución: $Y_d \mid n_d, \boldsymbol{\theta}_d \sim \text{Multinomial}(n_d, \boldsymbol{\theta}_d)$

::: {.callout-important}

### Código de `Stan`

```stan
data {
  int<lower=1> D; // número de dominios 
  int<lower=1> P; // categorías
  int<lower=1> K; // cantidad de regresores
  int hat_y[D, P]; // matriz de datos
  matrix[D, K] X_obs; // matriz de covariables
  int<lower=1> D1; // número de dominios 
  matrix[D1, K] X_pred; // matriz de covariables
}
```
:::

## Modelo en `Stan`: parameters y  transformed parameters

::: {.callout-important}

### Código de `Stan`

```stan
parameters {
  matrix[P-1, K] beta;// matriz de parámetros 
  vector<lower=0>[P-1] sigma_u;       // random effects standard deviations
  // declare L_u to be the Choleski factor of a 2x2 correlation matrix
  cholesky_factor_corr[P-1] L_u;
  matrix[P-1, D] z_u;                  
}

transformed parameters {
  simplex[P] theta[D];// vector de parámetros;
  real num[D, P];
  real den[D];
  // this transform random effects so that they have the correlation
  // matrix specified by the correlation matrix above
  matrix[P-1, D] u; // random effect matrix
  u = diag_pre_multiply(sigma_u, L_u) * z_u;
  
  for(d in 1:D){
    num[d, 1] = 1;
    num[d, 2] = exp(X_obs[d, ] * beta[1, ]' + u[1, d]) ;
    num[d, 3] = exp(X_obs[d, ] * beta[2, ]' + u[2, d]) ;
    
    den[d] = sum(num[d, ]);
  }
  
  for(d in 1:D){
    for(p in 2:P){
    theta[d, p] = num[d, p]/den[d];
    }
    theta[d, 1] = 1/den[d];
  }
}

```

:::

## Modelo en `Stan`: model y  generated quantities

::: {.callout-important}

### Código de `Stan`

```stan
model {
  L_u ~ lkj_corr_cholesky(1); // LKJ prior for the correlation matrix
  to_vector(z_u) ~ normal(0, 10000);
  // sigma_u ~ cauchy(0, 50);
  sigma_u ~ inv_gamma(0.0001, 0.0001);
  
  for(p in 2:P){
    for(k in 1:K){
      beta[p-1, k] ~ normal(0, 10000);
    }
    }
  
  for(d in 1:D){
    target += multinomial_lpmf(hat_y[d, ] | theta[d, ]); 
  }
}

  
generated quantities {
  matrix[D1,P] theta_pred;
  matrix[2, 2] Omega;
  Omega = L_u * L_u'; // so that it return the correlation matrix
  
 theta_pred = pred_theta(X_pred, P, beta);
}

```

:::

## Modelo en `Stan`: functions 

::: {.callout-important}

### Código de `Stan`

```stan
functions {
  matrix pred_theta(matrix Xp, int p, matrix beta){
  int D1 = rows(Xp);
  real num1[D1, p];
  real den1[D1];
  matrix[D1,p] theta_p;
  
  for(d in 1:D1){
    num1[d, 1] = 1;
    num1[d, 2] = exp(Xp[d, ] * beta[1, ]' ) ;
    num1[d, 3] = exp(Xp[d, ] * beta[2, ]' ) ;
    
    den1[d] = sum(num1[d, ]);
  }
  
  for(d in 1:D1){
    for(i in 2:p){
    theta_p[d, i] = num1[d, i]/den1[d];
    }
    theta_p[d, 1] = 1/den1[d];
   }

  return theta_p  ;
  }
  
}

```
:::

# Preparando insumos para `STAN`

## Lectura y adecuación de covariables
  
::: {.callout-tip}

### Código de `R`

```{r}
statelevel_predictors_df <-
  readRDS('data/empleo/statelevel_predictors_df_dam2.rds') 
## Estandarizando las variables para controlar el efecto de la escala. 
statelevel_predictors_df %<>%
  mutate_at(vars("luces_nocturnas", 
                 "cubrimiento_cultivo",
                 "cubrimiento_urbano",
                 "modificacion_humana",
                 "accesibilidad_hospitales",
                 "accesibilidad_hosp_caminado"),
            function(x)as.numeric(scale(x)))
```
:::

## Seleccionar las variables del modelo y crear matriz de covariables.
  
::: {.callout-tip}

### Código de `R`

```{r}
names_cov <- c( "dam2", "tasa_desocupacion",
    "material_paredes", "piso_tierra",   "luces_nocturnas",
    "cubrimiento_cultivo",  "modificacion_humana"
  )

X_pred <-
  anti_join(statelevel_predictors_df %>% select(all_of(names_cov)),
            indicador_dam1 %>% select(dam2))
```
:::

En el bloque de código se identifican que dominios serán los predichos.  

::: {.callout-tip}

### Código de `R`

```{r}
X_pred %>% select(dam2) %>% 
  saveRDS(file = "data/empleo/dam_pred.rds")
```
:::

## Obteniendo la matrix 

Creando la matriz de covariables para los dominios no observados (`X_pred`) y los observados (`X_obs`)

::: {.callout-tip}

### Código de `R`
  
```{r, eval=FALSE}
X_pred %<>%
  data.frame() %>%
  select(-dam2)  %>%  as.matrix()
```
:::

## Identificando los dominios para realizar estimación del modelo

::: {.callout-tip}

### Código de `R`
```{r, eval=FALSE}
X_obs <- inner_join(
  indicador_dam1 %>% select(dam2, id_orden),
  statelevel_predictors_df %>% select(all_of(names_cov))
) %>%
  arrange(id_orden) %>%
  data.frame() %>%
  select(-dam2, -id_orden)  %>%  as.matrix()
```
:::

## Calculando el $n$ efectivo y el $\tilde{y}$ 

::: {.callout-tip}

### Código de `R`

```{r,eval=FALSE}
D <- nrow(indicador_dam1)
P <- 3 # Ocupado, desocupado, inactivo.
Y_tilde <- matrix(NA, D, P)
n_tilde <- matrix(NA, D, P)
Y_hat <- matrix(NA, D, P)

# n efectivos ocupado
n_tilde[,1] <- (indicador_dam1$Ocupado*(1 - indicador_dam1$Ocupado))/indicador_dam1$Ocupado_var
Y_tilde[,1] <- n_tilde[,1]* indicador_dam1$Ocupado
```
:::

## $n$ efectivos desocupado y Inactivo

::: {.callout-tip}

### Código de `R`

```{r,eval=FALSE}
# n efectivos desocupado

n_tilde[,2] <- (indicador_dam1$Desocupado*(1 - indicador_dam1$Desocupado))/indicador_dam1$Desocupado_var
Y_tilde[,2] <- n_tilde[,2]* indicador_dam1$Desocupado

# n efectivos Inactivo
n_tilde[,3] <- (indicador_dam1$Inactivo*(1 - indicador_dam1$Inactivo))/indicador_dam1$Inactivo_var
Y_tilde[,3] <- n_tilde[,3]* indicador_dam1$Inactivo

```
:::

##  Validamos la coherencia de los cálculos realizados 

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
ni_hat = rowSums(Y_tilde)
Y_hat[,1] <- ni_hat* indicador_dam1$Ocupado
Y_hat[,2] <- ni_hat* indicador_dam1$Desocupado
Y_hat[,3] <- ni_hat* indicador_dam1$Inactivo
Y_hat <- round(Y_hat)

png("data/img/theta_ajustado.png",
    width = 1200, height = 400, res = 120)
hat_p <- Y_hat/rowSums(Y_hat)
par(mfrow = c(1,3))
plot(hat_p[,1],indicador_dam1$Ocupado)
abline(a = 0,b=1,col = "red")
plot(hat_p[,2],indicador_dam1$Desocupado)
abline(a = 0,b=1,col = "red")
plot(hat_p[,3],indicador_dam1$Inactivo)
abline(a = 0,b=1,col = "red")
dev.off()

```
:::

##  Validamos la coherencia de los cálculos realizados 

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("data/img/theta_ajustado.png")
```  

## Compilando el modelo 
::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
X1_obs <- cbind(matrix(1,nrow = D,ncol = 1),X_obs)
K = ncol(X1_obs)
D1 <- nrow(X_pred)
X1_pred <- cbind(matrix(1,nrow = D1,ncol = 1),X_pred)

sample_data <- list(D = D,
                    P = P,
                    K = K,
                    y_tilde = Y_hat,
                    X_obs = X1_obs,
                    X_pred = X1_pred,
                    D1 = D1)
```
:::

## Ajuste del modelo en R

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE}
fit_mcmc2 <- stan(
  file = "data/empleo/modelosStan/00 Multinomial_simple_no_cor.stan",  # Stan program
  data = sample_data,    # named list of data
  verbose = TRUE,
  warmup = 1000,          # number of warmup iterations per chain
  iter = 2000,            # total number of iterations per chain
  cores = 4,              # number of cores (could use one per chain)
)

saveRDS(fit_mcmc2,
        "data/empleo/fit_multinomial_no_cor.Rds")
```
:::

## Valiando el modelo: Cadenas del modelo
::: {.callout-tip}

### Código de `R`

```{r, echo=TRUE, eval=FALSE}
fit <- readRDS("data/empleo/fit_multinomial_no_cor.Rds")

theta_dir <- indicador_dam1 %>%  
  transmute(dam2,
    n = n_desocupado + n_ocupado + n_inactivo,
            Ocupado, Desocupado, Inactivo) 


y_pred_B <- as.array(fit, pars = "theta") %>%
  as_draws_matrix()

rowsrandom <- sample(nrow(y_pred_B), 100)
```
:::

## Valiando el modelo: Organizando las cadenas 

::: {.callout-tip}

### Código de `R`

```{r, echo=TRUE, eval=FALSE}
theta_1<-  grep(pattern = "1]",x = colnames(y_pred_B),value = TRUE)
theta_2<-  grep(pattern = "2]",x = colnames(y_pred_B),value = TRUE)
theta_3<-  grep(pattern = "3]",x = colnames(y_pred_B),value = TRUE)
y_pred1 <- y_pred_B[rowsrandom,theta_1 ]
y_pred2 <- y_pred_B[rowsrandom,theta_2 ]
y_pred3 <- y_pred_B[rowsrandom,theta_3 ]
```
:::

## Valiando el modelo: PPC 

::: {.callout-tip}

### Código de `R`

```{r, echo=TRUE, eval=FALSE}
color_scheme_set("brightblue")
theme_set(theme_bw(base_size = 15))

p1 <- ppc_dens_overlay(y = as.numeric(theta_dir$Ocupado), y_pred1)/
  ppc_dens_overlay(y = as.numeric(theta_dir$Desocupado), y_pred2)/
  ppc_dens_overlay(y = as.numeric(theta_dir$Inactivo), y_pred3)

ggsave(filename = "data/img/ppc_empleo.png",plot = p1, scale = 2)

```
:::

## Valiando el modelo : Resultados 

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("data/img/ppc_empleo.png")
```  



## Diagnóstico preliminar

::: {.callout-tip}

### Código de `R`

```{r, eval=FALSE, echo=TRUE}
p1 <- mcmc_trace(fit, pars = c("beta[1,1]", "beta[2,1]")) /
mcmc_trace(fit, pars = c("beta[1,2]", "beta[2,2]"))

ggsave(filename = "data/img/ppc_empleo2.png",
       plot = p1,
       scale = 2)

```
:::


```{r echo=FALSE, out.width = "800px", out.height="200px",fig.align='center'}
knitr::include_graphics("data/img/ppc_empleo2.png")
```  

Evalúa la convergencia de las cadenas y la estabilidad de los efectos aleatorios.


# Conclusiones

* El modelo multinomial permite integrar simultáneamente múltiples categorías del mercado laboral.

* La estructura jerárquica capta la variabilidad entre dominios y reduce la inestabilidad de los estimadores.

* Este enfoque es adecuado para la producción de indicadores regionales coherentes y comparables.




# Referencias


